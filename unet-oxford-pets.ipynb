{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"notebookId":"130d5172-c6db-4f08-925b-fdeca6d30295","notebookPath":"6/Seminar_6_Intro_to_DL.ipynb","kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# UNET_OXFORD-PETS","metadata":{"cellId":"w73qg0hrbkqecugr0y37"}},{"cell_type":"code","source":"#!g1.1\ndataset[0]","metadata":{"cellId":"kpq7tpndyqgdnjshm3vdw","collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\ndataset[0][0]","metadata":{"cellId":"3eo73h2gmjy4lpc30qgch5","collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\nplt.imshow(dataset[0][1])","metadata":{"cellId":"o50ldpulo1q7zb2pf9x1zd","collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\ndataset[100][0]","metadata":{"cellId":"0rcpasdv3mhia18xqqtmowe","collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\nplt.imshow(dataset[100][1])","metadata":{"cellId":"pbazo8hkvwno87lhvk1jh","collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Transformer 1","metadata":{}},{"cell_type":"code","source":"#!g1.1\ntransform = T.Compose(\n    [\n        T.Resize((128, 128)),\n        T.ToTensor(),\n    ]\n)\n\ntarget_transform = T.Compose(\n    [\n        T.Resize((128, 128)),\n        T.PILToTensor(),\n        T.Lambda(lambda x: (x - 1).long())\n    ]\n)\n\ntrain_dataset = OxfordIIITPet('../datasets/pets', transform=transform, target_transform=target_transform, target_types='segmentation')\nvalid_dataset = OxfordIIITPet('../datasets/pets', transform=transform, split='test', target_transform=target_transform, target_types='segmentation')","metadata":{"cellId":"9nlirgzrp7mofjzbkqazr","collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Ttransformer 2","metadata":{}},{"cell_type":"code","source":"#!g1.1\ntransform = T.Compose(\n    [\n        T.Resize((256, 256)),\n        T.ToTensor(),\n    ]\n)\n\ntarget_transform = T.Compose(\n    [\n        T.Resize((256, 256)),\n        T.PILToTensor(),\n        T.Lambda(lambda x: (x - 1).long())\n    ]\n)\n\ntrain_dataset = OxfordIIITPet('../datasets/pets', transform=transform, target_transform=target_transform, target_types='segmentation')\nvalid_dataset = OxfordIIITPet('../datasets/pets', transform=transform, split='test', target_transform=target_transform, target_types='segmentation')","metadata":{"cellId":"9nlirgzrp7mofjzbkqazr","collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\nfrom torch.utils.data import DataLoader\n\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=8, pin_memory=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=True, num_workers=8, pin_memory=True)","metadata":{"cellId":"ffs63ugzil8wz2x0tofrb7","collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\nfrom tqdm import tqdm\n\n\ndef train(model) -> float:\n    model.train()\n\n    train_loss = 0\n    total = 0\n    correct = 0\n\n    for x, y in tqdm(train_loader, desc='Train'):\n        bs = y.size(0)\n\n        x, y = x.to(device), y.squeeze(1).to(device)\n\n        optimizer.zero_grad()\n\n        output = model(x)\n\n        loss = loss_fn(output.reshape(bs, 3, -1), y.reshape(bs, -1))\n\n        train_loss += loss.item()\n\n        loss.backward()\n\n        optimizer.step()\n\n        _, y_pred = output.max(dim=1)\n        total += y.size(0) * y.size(1) * y.size(2)\n        correct += (y == y_pred).sum().item()\n\n    train_loss /= len(train_loader)\n    accuracy = correct / total\n\n    return train_loss, accuracy","metadata":{"cellId":"dzddyzfdiilirsiodtrnm","collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\n@torch.inference_mode()\ndef evaluate(model, loader) -> tuple[float, float]:\n    model.eval()\n\n    total_loss = 0\n    total = 0\n    correct = 0\n\n    for x, y in tqdm(loader, desc='Evaluation'):\n        bs = y.size(0)\n\n        x, y = x.to(device), y.squeeze(1).to(device)\n\n        output = model(x)\n\n        loss = loss_fn(output.reshape(bs, 3, -1), y.reshape(bs, -1))\n\n        total_loss += loss.item()\n\n        _, y_pred = output.max(dim=1)\n        total += y.size(0) * y.size(1) * y.size(2)\n        correct += (y == y_pred).sum().item()\n\n    total_loss /= len(loader)\n    accuracy = correct / total\n\n    return total_loss, accuracy","metadata":{"cellId":"ltg96xv7y10dphu68h0slk","collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\nfrom IPython.display import clear_output\n\n\ndef plot_stats(\n    train_loss: list[float],\n    valid_loss: list[float],\n    train_accuracy: list[float],\n    valid_accuracy: list[float],\n    title: str\n):\n    plt.figure(figsize=(16, 8))\n\n    plt.title(title + ' loss')\n\n    plt.plot(train_loss, label='Train loss')\n    plt.plot(valid_loss, label='Valid loss')\n    plt.legend()\n    plt.grid()\n\n    plt.show()\n\n    plt.figure(figsize=(16, 8))\n\n    plt.title(title + ' accuracy')\n    \n    plt.plot(train_accuracy, label='Train accuracy')\n    plt.plot(valid_accuracy, label='Valid accuracy')\n    plt.legend()\n    plt.grid()\n\n    plt.show()","metadata":{"cellId":"2vhgdldktuvrwfy6oziw4k","collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\nimport numpy as np\nfrom PIL import Image\n\n\n@torch.inference_mode()\ndef visualize(model, batch):\n    model.eval()\n\n    xs, ys = batch\n    \n    to_pil = T.ToPILImage()\n\n    for i, (x, y) in enumerate(zip(xs, ys)):\n        prediction = model(x.unsqueeze(0).cuda()).squeeze(0).max(dim=0)[1]\n\n        fig, ax = plt.subplots(1, 3, figsize=(24, 8), facecolor='white')\n\n        ax[0].imshow(to_pil(x))\n        ax[1].imshow(to_pil(y.to(torch.uint8)))\n        ax[2].imshow(to_pil(prediction.to(torch.uint8)))\n\n        ax[0].axis('off')\n        ax[1].axis('off')\n        ax[2].axis('off')\n\n        ax[0].set_title('Original image')\n        ax[1].set_title('Segmentation mask')\n        ax[2].set_title('Prediction')\n\n        plt.subplots_adjust(wspace=0, hspace=0.1)\n        plt.show()\n\n        if i >= 9:\n            break","metadata":{"cellId":"p3nfrmyozeix0mnh462i","collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\ndef whole_train_valid_cycle(model, num_epochs, title):\n    train_loss_history, valid_loss_history = [], []\n    train_accuracy_history, valid_accuracy_history = [], []\n\n    for epoch in range(num_epochs):\n        train_loss, train_accuracy = train(model)\n        valid_loss, valid_accuracy = evaluate(model, valid_loader)\n\n        train_loss_history.append(train_loss)\n        valid_loss_history.append(valid_loss)\n\n        train_accuracy_history.append(train_accuracy)\n        valid_accuracy_history.append(valid_accuracy)\n\n        clear_output()\n\n        plot_stats(\n            train_loss_history, valid_loss_history,\n            train_accuracy_history, valid_accuracy_history,\n            title\n        )\n\n        visualize(model, next(iter(valid_loader)))","metadata":{"cellId":"okqkrmopaqooy667aad37","collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model 1","metadata":{}},{"cell_type":"code","source":"#!g1.1\nimport torch.nn as nn\n\n\ndef conv_plus_conv(in_channels: int, out_channels: int):\n    \"\"\"\n    Makes UNet block\n    :param in_channels: input channels\n    :param out_channels: output channels\n    :return: UNet block\n    \"\"\"\n    return nn.Sequential(\n        nn.Conv2d(\n            in_channels=in_channels,\n            out_channels=out_channels,\n            kernel_size=3,\n            stride=1,\n            padding=1\n        ),\n        nn.BatchNorm2d(num_features=out_channels),\n        nn.LeakyReLU(0.2),\n        nn.Conv2d(\n            in_channels=out_channels,\n            out_channels=out_channels,\n            kernel_size=3,\n            stride=1,\n            padding=1\n        ),\n        nn.BatchNorm2d(num_features=out_channels),\n        nn.LeakyReLU(0.2),\n    )\n\n\nclass UNET(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        base_channels = 16\n\n        self.down1 = conv_plus_conv(3, base_channels)\n        self.down2 = conv_plus_conv(base_channels, base_channels * 2)\n\n        self.up1 = conv_plus_conv(base_channels * 2, base_channels)\n        self.up2 = conv_plus_conv(base_channels * 4, base_channels)\n\n        self.bottleneck = conv_plus_conv(base_channels * 2, base_channels * 2)\n\n        self.out = nn.Conv2d(in_channels=base_channels, out_channels=3, kernel_size=1)\n\n        self.downsample = nn.MaxPool2d(kernel_size=2, stride=2)\n\n    def forward(self, x):\n        # x.shape = (N, N, 3)\n\n        residual1 = self.down1(x)  # x.shape: (N, N, 3) -> (N, N, base_channels)\n        x = self.downsample(residual1)  # x.shape: (N, N, base_channels) -> (N // 2, N // 2, base_channels)\n\n        residual2 = self.down2(x)  # x.shape: (N // 2, N // 2, base_channels) -> (N // 2, N // 2, base_channels * 2)\n        x = self.downsample(residual2)  # x.shape: (N // 2, N // 2, base_channels * 2) -> (N // 4, N // 4, base_channels * 2)\n\n        # LATENT SPACE DIMENSION DIM = N // 4\n        # SOME MANIPULATION MAYBE\n        x = self.bottleneck(x)  # x.shape: (N // 4, N // 4, base_channels * 2) -> (N // 4, N // 4, base_channels * 2)\n        # SOME MANIPULATION MAYBE\n        # LATENT SPACE DIMENSION DIM = N // 4\n\n        x = nn.functional.interpolate(x, scale_factor=2)  # x.shape: (N // 4, N // 4, base_channels * 2) -> (N // 2, N // 2, base_channels * 2)\n        x = torch.cat((x, residual2), dim=1)  # x.shape: (N // 2, N // 2, base_channels * 2) -> (N // 2, N // 2, base_channels * 4)\n        x = self.up2(x)  # x.shape: (N // 2, N // 2, base_channels * 4) -> (N // 2, N // 2, base_channels)\n\n        x = nn.functional.interpolate(x, scale_factor=2)  # x.shape: (N // 2, N // 2, base_channels) -> (N, N, base_channels)\n        x = torch.cat((x, residual1), dim=1)  # x.shape: (N, N, base_channels) -> (N, N, base_channels * 2)\n        x = self.up1(x)  # x.shape: (N, N, base_channels * 2) -> (N, N, base_channels)\n\n        x = self.out(x)  # x.shape: (N, N, base_channels) -> (N, N, 3)\n\n        return x","metadata":{"cellId":"ozusohnhimkfrglrfxmvbn","collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model 2","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\n\n\ndef conv_plus_conv(in_channels: int, out_channels: int):\n    \"\"\"\n    Makes UNet block\n    :param in_channels: input channels\n    :param out_channels: output channels\n    :return: UNet block\n    \"\"\"\n    return nn.Sequential(\n        nn.Conv2d(\n            in_channels=in_channels,\n            out_channels=out_channels,\n            kernel_size=3,\n            stride=1,\n            padding=1\n        ),\n        nn.BatchNorm2d(num_features=out_channels),\n        nn.LeakyReLU(0.2),\n        nn.Conv2d(\n            in_channels=out_channels,\n            out_channels=out_channels,\n            kernel_size=3,\n            stride=1,\n            padding=1\n        ),\n        nn.BatchNorm2d(num_features=out_channels),\n        nn.LeakyReLU(0.2),\n    )\n\nclass UNET(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        base_channels = 32  # Increased base_channels for better accuracy\n\n        # Downsampling blocks\n        self.down1 = conv_plus_conv(3, base_channels)\n        self.down2 = conv_plus_conv(base_channels, base_channels * 2)\n        self.down3 = conv_plus_conv(base_channels * 2, base_channels * 4)\n        self.down4 = conv_plus_conv(base_channels * 4, base_channels * 8)\n        self.down5 = conv_plus_conv(base_channels * 8, base_channels * 16)\n        self.down6 = conv_plus_conv(base_channels * 16, base_channels * 32)\n\n        # Upsampling blocks\n        self.up1 = conv_plus_conv(base_channels * 64, base_channels * 16)\n        self.up2 = conv_plus_conv(base_channels * 32, base_channels * 8)\n        self.up3 = conv_plus_conv(base_channels * 16, base_channels * 4)\n        self.up4 = conv_plus_conv(base_channels * 8, base_channels * 2)\n        self.up5 = conv_plus_conv(base_channels * 4, base_channels)\n\n        # Bottleneck block\n        self.bottleneck = conv_plus_conv(base_channels * 32, base_channels * 32)\n\n        # Output layer (corrected number of channels)\n        self.out = nn.Conv2d(in_channels=base_channels * 2, out_channels=3, kernel_size=1)\n\n        self.downsample = nn.MaxPool2d(kernel_size=2, stride=2)\n\n    def forward(self, x):\n        # Downsampling path\n        residual1 = self.down1(x)\n        x = self.downsample(residual1)\n\n        residual2 = self.down2(x)\n        x = self.downsample(residual2)\n\n        residual3 = self.down3(x)\n        x = self.downsample(residual3)\n\n        residual4 = self.down4(x)\n        x = self.downsample(residual4)\n\n        residual5 = self.down5(x)\n        x = self.downsample(residual5)\n\n        residual6 = self.down6(x)\n        x = self.downsample(residual6)\n\n        # Bottleneck\n        x = self.bottleneck(x)\n\n        # Upsampling path\n        x = nn.functional.interpolate(x, scale_factor=2)\n        x = torch.cat((x, residual6), dim=1)\n        x = self.up1(x)\n\n        x = nn.functional.interpolate(x, scale_factor=2)\n        x = torch.cat((x, residual5), dim=1)\n        x = self.up2(x)\n\n        x = nn.functional.interpolate(x, scale_factor=2)\n        x = torch.cat((x, residual4), dim=1)\n        x = self.up3(x)\n\n        x = nn.functional.interpolate(x, scale_factor=2)\n        x = torch.cat((x, residual3), dim=1)\n        x = self.up4(x)\n\n        x = nn.functional.interpolate(x, scale_factor=2)\n        x = torch.cat((x, residual2), dim=1)\n        x = self.up5(x)\n\n        x = nn.functional.interpolate(x, scale_factor=2)\n        x = torch.cat((x, residual1), dim=1)\n\n        # Output layer (fix input channels to match concatenated channels)\n        x = self.out(x)\n\n        return x\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\nprint(device)\nprint(torch.cuda.get_device_name())\n\nloss_fn = nn.CrossEntropyLoss()","metadata":{"cellId":"urs7wf6ytb94o3e0mg53lv","collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loss_fn = nn.CrossEntropyLoss()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\nfrom torch.optim import Adam\n\nmodel = UNET().to(device)\n\noptimizer = Adam(model.parameters(), lr=1e-3)","metadata":{"cellId":"iy1d1vftkjk8ms7024k2o2","collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\nwhole_train_valid_cycle(model, 15, 'UNET segmentation')","metadata":{"cellId":"z9w9akylmqew1t0dnf3faq","collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\nvisualize(model, next(iter(train_loader)))","metadata":{"cellId":"hpcvx88xo7cojbn7t1zcwc","collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Predictions for 200 random samples from the validation dataset","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom torch.utils.data import Subset\nfrom tqdm import tqdm\n\nnp.random.seed(100)\n\n# Random indices\nidx = np.random.randint(len(valid_dataset), size=200)\n\n# Subset of the validation dataset\nvalid_subset = Subset(valid_dataset, idx)\n\nmodel.eval() \n\npredictions = []\n\nvalid_loader = torch.utils.data.DataLoader(valid_subset, batch_size=16, shuffle=False)\n\nwith torch.no_grad():  # Disable gradient computation for inference\n    for inputs, _ in tqdm(valid_loader, desc=\"Making predictions\"):\n        \n        inputs = inputs.to(device)\n        \n        outputs = model(inputs)\n        \n        preds = outputs.argmax(dim=1, keepdim=True)\n\n        predictions.append(preds.cpu())  \n\npredictions_tensor = torch.cat(predictions, dim=0)\n\n# shape [200, 1, 256, 256]\nassert predictions_tensor.shape == (200, 1, 256, 256), f\"Shape mismatch: {predictions_tensor.shape}\"\n\n# Converting predictions to uint8 before saving to reduce storage space\npredictions_tensor = predictions_tensor.to(torch.uint8)\n\ntorch.save(predictions_tensor, 'predictions.pt')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}